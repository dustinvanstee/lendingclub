{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Modeling / Evaluation /Deployment to WML using Pyspark\n",
    "<img src=\"https://github.com/CatherineCao2016/lendingclub/raw/master/modeling.png\" width=\"800\" height=\"500\" align=\"middle\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are trying to predict the likliehood of default given borrowers data.  \n",
    "Here are three ML algorithms are tested using Spark and Pipelines API in pyspark.\n",
    "\n",
    "1. Logistic Regression\n",
    "2. Decision Tree\n",
    "3. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6e460ddcc3b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDoubleType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = 999\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "from datetime import datetime\n",
    "import math\n",
    "import urllib3, requests, json\n",
    "\n",
    "loan_df = pd.read_pickle(\"01-dataprep-loan_short_df.pkl\")\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.feature import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Load Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.printSchema of DataFrame[LOAN_STATUS: string, ISSUE_D: bigint, LOAN_AMNT: bigint, EMP_TITLE: string, EMP_LENGTH: string, VERIFICATION_STATUS: string, HOME_OWNERSHIP: string, ANNUAL_INC: double, PURPOSE: string, INQ_LAST_6MTHS: bigint, DESC: string, OPEN_ACC: bigint, PUB_REC: bigint, REVOL_UTIL: double, DTI: double, TOTAL_ACC: bigint, DELINQ_2YRS: bigint, EARLIEST_CR_LINE: bigint, MTHS_SINCE_LAST_DELINQ: double, ADDR_STATE: string, TERM: string, DEFAULT: bigint, EMP_LISTED: bigint, EMPTY_DESC: bigint, EMP_NA: bigint, DELING_EVER: bigint, TIME_HISTORY: bigint]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>ISSUE_D</th>\n",
       "      <th>LOAN_AMNT</th>\n",
       "      <th>ANNUAL_INC</th>\n",
       "      <th>INQ_LAST_6MTHS</th>\n",
       "      <th>OPEN_ACC</th>\n",
       "      <th>PUB_REC</th>\n",
       "      <th>REVOL_UTIL</th>\n",
       "      <th>DTI</th>\n",
       "      <th>TOTAL_ACC</th>\n",
       "      <th>DELINQ_2YRS</th>\n",
       "      <th>EARLIEST_CR_LINE</th>\n",
       "      <th>MTHS_SINCE_LAST_DELINQ</th>\n",
       "      <th>DEFAULT</th>\n",
       "      <th>EMP_LISTED</th>\n",
       "      <th>EMPTY_DESC</th>\n",
       "      <th>EMP_NA</th>\n",
       "      <th>DELING_EVER</th>\n",
       "      <th>TIME_HISTORY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>39999</td>\n",
       "      <td>39999</td>\n",
       "      <td>39999</td>\n",
       "      <td>39999</td>\n",
       "      <td>39999</td>\n",
       "      <td>39999</td>\n",
       "      <td>39999</td>\n",
       "      <td>39999</td>\n",
       "      <td>39999</td>\n",
       "      <td>39999</td>\n",
       "      <td>39999</td>\n",
       "      <td>39999</td>\n",
       "      <td>39999</td>\n",
       "      <td>39999</td>\n",
       "      <td>39999</td>\n",
       "      <td>39999</td>\n",
       "      <td>39999</td>\n",
       "      <td>39999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>1.28886233483833523E18</td>\n",
       "      <td>11220.381759543989</td>\n",
       "      <td>69005.63250381262</td>\n",
       "      <td>0.889347233680842</td>\n",
       "      <td>9.304557613940348</td>\n",
       "      <td>0.055451386284657116</td>\n",
       "      <td>48.87473636840911</td>\n",
       "      <td>13.328587714692953</td>\n",
       "      <td>22.113227830695767</td>\n",
       "      <td>0.1474036850921273</td>\n",
       "      <td>8.5362744012600922E17</td>\n",
       "      <td>35.90692017301288</td>\n",
       "      <td>0.14262856571414284</td>\n",
       "      <td>0.9379734493362334</td>\n",
       "      <td>0.3314582864571614</td>\n",
       "      <td>0.0271756793919848</td>\n",
       "      <td>0.35395884897122426</td>\n",
       "      <td>5037.440911022775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>2.8809946600352852E16</td>\n",
       "      <td>7458.321880039553</td>\n",
       "      <td>63903.73691587774</td>\n",
       "      <td>1.1088136654975094</td>\n",
       "      <td>4.414574883524405</td>\n",
       "      <td>0.23817652494183308</td>\n",
       "      <td>28.313485728157534</td>\n",
       "      <td>6.680935935424673</td>\n",
       "      <td>11.4190903560703</td>\n",
       "      <td>0.4959183335662212</td>\n",
       "      <td>2.15614900508990368E17</td>\n",
       "      <td>13.098574359254316</td>\n",
       "      <td>0.34969803438221314</td>\n",
       "      <td>0.24120678313573807</td>\n",
       "      <td>0.4707432749549588</td>\n",
       "      <td>0.16259711806690522</td>\n",
       "      <td>0.47820257139793804</td>\n",
       "      <td>2501.1879606625066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>1180656000000000000</td>\n",
       "      <td>500</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-757382400000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>1322697600000000000</td>\n",
       "      <td>35000</td>\n",
       "      <td>6000000.0</td>\n",
       "      <td>8</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>99.9</td>\n",
       "      <td>29.99</td>\n",
       "      <td>90</td>\n",
       "      <td>11</td>\n",
       "      <td>1225497600000000000</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary                 ISSUE_D           LOAN_AMNT         ANNUAL_INC  \\\n",
       "0   count                   39999               39999              39999   \n",
       "1    mean  1.28886233483833523E18  11220.381759543989  69005.63250381262   \n",
       "2  stddev   2.8809946600352852E16   7458.321880039553  63903.73691587774   \n",
       "3     min     1180656000000000000                 500             4000.0   \n",
       "4     max     1322697600000000000               35000          6000000.0   \n",
       "\n",
       "       INQ_LAST_6MTHS           OPEN_ACC               PUB_REC  \\\n",
       "0               39999              39999                 39999   \n",
       "1   0.889347233680842  9.304557613940348  0.055451386284657116   \n",
       "2  1.1088136654975094  4.414574883524405   0.23817652494183308   \n",
       "3                   0                  2                     0   \n",
       "4                   8                 44                     4   \n",
       "\n",
       "           REVOL_UTIL                 DTI           TOTAL_ACC  \\\n",
       "0               39999               39999               39999   \n",
       "1   48.87473636840911  13.328587714692953  22.113227830695767   \n",
       "2  28.313485728157534   6.680935935424673    11.4190903560703   \n",
       "3                 0.0                 0.0                   2   \n",
       "4                99.9               29.99                  90   \n",
       "\n",
       "          DELINQ_2YRS        EARLIEST_CR_LINE MTHS_SINCE_LAST_DELINQ  \\\n",
       "0               39999                   39999                  39999   \n",
       "1  0.1474036850921273   8.5362744012600922E17      35.90692017301288   \n",
       "2  0.4959183335662212  2.15614900508990368E17     13.098574359254316   \n",
       "3                   0     -757382400000000000                    0.0   \n",
       "4                  11     1225497600000000000                  120.0   \n",
       "\n",
       "               DEFAULT           EMP_LISTED          EMPTY_DESC  \\\n",
       "0                39999                39999               39999   \n",
       "1  0.14262856571414284   0.9379734493362334  0.3314582864571614   \n",
       "2  0.34969803438221314  0.24120678313573807  0.4707432749549588   \n",
       "3                    0                    0                   0   \n",
       "4                    1                    1                   1   \n",
       "\n",
       "                EMP_NA          DELING_EVER        TIME_HISTORY  \n",
       "0                39999                39999               39999  \n",
       "1   0.0271756793919848  0.35395884897122426   5037.440911022775  \n",
       "2  0.16259711806690522  0.47820257139793804  2501.1879606625066  \n",
       "3                    0                    0                1095  \n",
       "4                    1                    1               23892  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_spark_read = spark.read.parquet(\"home/lending_club/loan_sub_kp\").cache()\n",
    "# loan_spark = spark.createDataFrame(loan_sub_kp.drop(['LOAN_STATUS', 'ISSUE_D', 'EMP_TITLE', 'DESC', 'MTHS_SINCE_LAST_DELINQ'], 1)).cache()\n",
    "print loan_spark_read.printSchema\n",
    "loan_spark_read.toPandas()\n",
    "loan_spark_read.describe().toPandas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocess the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create label column: covert long to double to avoid RF fit error\n",
    "loan_spark_read = loan_spark_read.withColumn('label', loan_spark_read['DEFAULT'].cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One-hot encoder for all categorical varaibles\n",
    "catCols = ['EMP_LENGTH', 'VERIFICATION_STATUS', 'HOME_OWNERSHIP', 'PURPOSE', 'ADDR_STATE', 'TERM']\n",
    "for catCol in catCols:\n",
    "    loan_spark_read = StringIndexer(inputCol=catCol, outputCol=catCol+\"Index\").fit(loan_spark_read).transform(loan_spark_read)\n",
    "    loan_spark_read = OneHotEncoder(inputCol=catCol+\"Index\", outputCol=catCol+\"classVec\").transform(loan_spark_read)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble feature vector\n",
    "numCols = ['LOAN_AMNT', 'ANNUAL_INC', 'INQ_LAST_6MTHS', 'OPEN_ACC', 'PUB_REC', 'REVOL_UTIL', 'DTI', 'TOTAL_ACC', 'DELINQ_2YRS', 'EMP_LISTED', 'EMPTY_DESC', 'EMP_NA', 'DELING_EVER', 'TIME_HISTORY']\n",
    "\n",
    "# Concatenate Numerical and Categorical Features, and then add to Vector Assembler \n",
    "assemblerInputs = map(lambda c: c + \"classVec\", catCols) + numCols\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features_non_scaled\")\n",
    "# Debug\n",
    "# assemblerInputs = numCols\n",
    "#assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features_non_scaled\")\n",
    "loan_spark = assembler.transform(loan_spark_read)\n",
    "\n",
    "\n",
    "scaler = StandardScaler(withMean=False, withStd=True, inputCol=\"features_non_scaled\", outputCol=\"features\")\n",
    "scalerModel = scaler.fit(loan_spark)\n",
    "loan_spark = scalerModel.transform(loan_spark)\n",
    "\n",
    "# keep useful variables\n",
    "selectedcols = [\"label\", \"features\"]\n",
    "loan_model = loan_spark.select(selectedcols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Split the data into training and testing sets  **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 27877\n",
      "Testing set size: 12122\n",
      "Distribution of Default and Non-Default in trainingData is:  [Row(label=0.0, count=23913), Row(label=1.0, count=3964)]\n"
     ]
    }
   ],
   "source": [
    "trainingData, testData = loan_model.randomSplit([0.7, 0.3], seed = 82)\n",
    "print \"Training set size: \" + str(trainingData.count())\n",
    "print \"Testing set size: \" + str(testData.count())\n",
    "print \"Distribution of Default and Non-Default in trainingData is: \", trainingData.groupBy(\"label\").count().take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Models\n",
    "\n",
    "Here is the method that was used to create model // model pipelines\n",
    "\n",
    "1.  Create Manual Logistic Regression run with Grid parameter search\n",
    "2.  Create Manual Decision Tree run with Grid parameter search\n",
    "3.  Create Manual Random Forest run with Grid parameter search\n",
    "\n",
    "4. Then build a pipeline using the best models found from grid search.\n",
    "\n",
    "5. Proceed to WML deployment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "** Use CrossValidator and ParamGridBuilder to search for best model **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create initial LogisticRegression model\n",
    "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", threshold=0.3)\n",
    "\n",
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam, [0.001, 0.1])\n",
    "             .addGrid(lr.elasticNetParam, [0.0,1.0])\n",
    "             .addGrid(lr.maxIter, [100])\n",
    "             .build())\n",
    "\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "\n",
    "# Create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=2)\n",
    "\n",
    "# Run cross validations\n",
    "lrCvModel = cv.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Use BinaryClassificationEvaluator to evaluate the model **\n",
    "\n",
    "Note that the default metric for the BinaryClassificationEvaluator is areaUnderROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "areaUnderROC for LR: 0.690960338722\n",
      "Cross tab for prediction vs actual table\n",
      "+----------------+----+---+\n",
      "|label_prediction| 0.0|1.0|\n",
      "+----------------+----+---+\n",
      "|             1.0|1512|229|\n",
      "|             0.0|9958|423|\n",
      "+----------------+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use test set here so we can measure the accuracy of our model on new data\n",
    "lr_uroc = evaluator.evaluate(lrCvModel.transform(testData))\n",
    "\n",
    "print \"areaUnderROC for LR: \" + str(lr_uroc)\n",
    "\n",
    "print \"Cross tab for prediction vs actual table\"\n",
    "lrCvModel.transform(testData).stat.crosstab(\"label\", \"prediction\").show()\n",
    "# lrCvModel.bestModel.transform(testData).toPandas()\n",
    "#print lrCvModel.bestModel.coefficients\n",
    "#print lrCvModel.bestModel.intercept\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numNodes =  921\n",
      "depth =  10\n",
      "areaUnderROC for DT: 0.47766473024\n",
      "Cross tab for prediction vs actual table\n",
      "+----------------+-----+---+\n",
      "|label_prediction|  0.0|1.0|\n",
      "+----------------+-----+---+\n",
      "|             1.0| 1651| 90|\n",
      "|             0.0|10136|245|\n",
      "+----------------+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "# Create initial Decision Tree Model\n",
    "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\", maxDepth=5)\n",
    "\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(dt.maxDepth, [10])\n",
    "             .addGrid(dt.maxBins, [40])\n",
    "             .build())\n",
    "\n",
    "\n",
    "# Create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=dt, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n",
    "\n",
    "# Run cross validations\n",
    "dtCvModel = cv.fit(trainingData)\n",
    "\n",
    "print \"numNodes = \", dtCvModel.bestModel.numNodes\n",
    "print \"depth = \", dtCvModel.bestModel.depth\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "\n",
    "predictions = dtCvModel.transform(testData)\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "dt_uroc = evaluator.evaluate(predictions)\n",
    "\n",
    "print \"areaUnderROC for DT: \" + str(dt_uroc)\n",
    "print \"Cross tab for prediction vs actual table\"\n",
    "dtCvModel.transform(testData).stat.crosstab(\"label\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "areaUnderROC for RF: 0.677956226197\n",
      "Cross tab for prediction vs actual table\n",
      "+----------------+-----+\n",
      "|label_prediction|  0.0|\n",
      "+----------------+-----+\n",
      "|             1.0| 1741|\n",
      "|             0.0|10381|\n",
      "+----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(rf.maxDepth, [2, 6])\n",
    "             .addGrid(rf.maxBins, [20, 40])\n",
    "             .addGrid(rf.numTrees, [5, 20])\n",
    "             .build())\n",
    "\n",
    "cv = CrossValidator(estimator=rf, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n",
    "\n",
    "# Run cross validations.  This can take about 6 minutes since it is training over 20 trees!\n",
    "rfCvModel = cv.fit(trainingData)\n",
    "\n",
    "predictions = rfCvModel.transform(testData)\n",
    "\n",
    "rf_uroc = evaluator.evaluate(predictions)\n",
    "\n",
    "print \"areaUnderROC for RF: \" + str(rf_uroc) #0.6918242957971713\n",
    "print \"Cross tab for prediction vs actual table\"\n",
    "rfCvModel.transform(testData).stat.crosstab(\"label\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "areaUnderROC for LR: 0.690960338722\n",
      "areaUnderROC for DT: 0.47766473024\n",
      "areaUnderROC for RF: 0.677956226197\n"
     ]
    }
   ],
   "source": [
    "print \"areaUnderROC for LR: \" + str(lr_uroc)\n",
    "print \"areaUnderROC for DT: \" + str(dt_uroc)\n",
    "print \"areaUnderROC for RF: \" + str(rf_uroc) #0.6918242957971713\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(94, {0: 0.002, 1: 0.0024, 2: 0.0034, 3: 0.0023, 4: 0.0056, 5: 0.0018, 6: 0.002, 7: 0.0026, 8: 0.0, 9: 0.0019, 10: 0.0038, 11: 0.0103, 12: 0.0108, 13: 0.0059, 14: 0.0127, 15: 0.0021, 16: 0.002, 17: 0.0018, 18: 0.0221, 19: 0.0028, 20: 0.0043, 21: 0.0058, 22: 0.0324, 23: 0.0027, 24: 0.0006, 25: 0.0019, 26: 0.0028, 27: 0.0007, 28: 0.001, 29: 0.0038, 30: 0.0044, 31: 0.003, 32: 0.0058, 33: 0.0004, 34: 0.0027, 35: 0.001, 36: 0.0016, 37: 0.0022, 38: 0.0038, 39: 0.002, 40: 0.001, 41: 0.0025, 42: 0.0014, 43: 0.0005, 44: 0.0007, 45: 0.0012, 46: 0.0031, 47: 0.0011, 48: 0.0018, 49: 0.0016, 50: 0.0054, 51: 0.0006, 52: 0.0003, 53: 0.0002, 54: 0.0029, 55: 0.0017, 56: 0.0012, 58: 0.0007, 59: 0.0007, 60: 0.001, 61: 0.0018, 62: 0.0006, 63: 0.0014, 64: 0.0008, 65: 0.0007, 66: 0.0017, 67: 0.0009, 68: 0.0005, 69: 0.0012, 70: 0.0011, 71: 0.0013, 72: 0.001, 74: 0.0003, 78: 0.0011, 79: 0.2323, 80: 0.055, 81: 0.0835, 82: 0.0698, 83: 0.034, 84: 0.0266, 85: 0.1285, 86: 0.0304, 87: 0.0303, 88: 0.0105, 89: 0.0217, 90: 0.0011, 91: 0.0065, 92: 0.0107, 93: 0.0337})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfCvModel.bestModel.featureImportances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment via Watson Machine Learning Service(WML)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/CatherineCao2016/lendingclub/raw/master/depolyment.png\" width=\"800\" height=\"500\" align=\"middle\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Pipeline for WML**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# inputdf should have a non-doubt DEFAULT column\n",
    "\n",
    "def build_model(inputdf):\n",
    "    \n",
    "    inputdf = inputdf.withColumn('label', inputdf['DEFAULT'].cast(DoubleType()))\n",
    "    \n",
    "    catCols = ['EMP_LENGTH', 'VERIFICATION_STATUS', 'HOME_OWNERSHIP', 'PURPOSE', 'ADDR_STATE', 'TERM']\n",
    "    \n",
    "    # to_do: is it possible use for loop to produce the following? so we could user-define variable list\n",
    "    SI1 = StringIndexer(inputCol='EMP_LENGTH', outputCol='EMP_LENGTH'+\"Index\")\n",
    "    SI2 = StringIndexer(inputCol='VERIFICATION_STATUS', outputCol='VERIFICATION_STATUS'+'Index')\n",
    "    SI3 = StringIndexer(inputCol='HOME_OWNERSHIP', outputCol='HOME_OWNERSHIP'+'Index')\n",
    "    SI4 = StringIndexer(inputCol='PURPOSE', outputCol='PURPOSE'+'Index')\n",
    "    SI5 = StringIndexer(inputCol='ADDR_STATE', outputCol='ADDR_STATE'+'Index')\n",
    "    SI6 = StringIndexer(inputCol='TERM', outputCol='TERM'+'Index')\n",
    "\n",
    "    OH1 = OneHotEncoder(inputCol='EMP_LENGTH' + 'Index', outputCol='EMP_LENGTH' + 'classVec')\n",
    "    OH2 = OneHotEncoder(inputCol='VERIFICATION_STATUS' + 'Index', outputCol='VERIFICATION_STATUS' + 'classVec')\n",
    "    OH3 = OneHotEncoder(inputCol='HOME_OWNERSHIP' + 'Index', outputCol='HOME_OWNERSHIP' + 'classVec')\n",
    "    OH4 = OneHotEncoder(inputCol='PURPOSE' + 'Index', outputCol='PURPOSE' + 'classVec')\n",
    "    OH5 = OneHotEncoder(inputCol='ADDR_STATE' + 'Index', outputCol='ADDR_STATE' + 'classVec')\n",
    "    OH6 = OneHotEncoder(inputCol='TERM' + 'Index', outputCol='TERM' + 'classVec')\n",
    "    \n",
    "    numCols = ['LOAN_AMNT', 'ANNUAL_INC', 'INQ_LAST_6MTHS', 'OPEN_ACC', 'PUB_REC', 'REVOL_UTIL', 'DTI', 'TOTAL_ACC', 'DELINQ_2YRS', 'EMP_LISTED', 'EMPTY_DESC', 'EMP_NA', 'DELING_EVER', 'TIME_HISTORY']\n",
    "    \n",
    "    assemblerInputs = map(lambda c: c + \"classVec\", catCols) + numCols\n",
    "    \n",
    "    assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features_non_scaled\")\n",
    "    \n",
    "    scaler = StandardScaler(withMean=False, withStd=True, inputCol=\"features_non_scaled\", outputCol=\"features\")\n",
    "    #scalerModel = scaler.fit(loan_spark)\n",
    "    #loan_spark = scalerModel.transform(loan_spark)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print \"Training Model...\"\n",
    "    \n",
    "    #lr_final = LogisticRegression(maxIter=10, regParam=0.1, elasticNetParam=0.0, threshold = 0.5, labelCol=\"label\", featuresCol=\"features\")\n",
    "    \n",
    "    rf_final_model = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", maxDepth = 6, maxBins = 60, numTrees = 20)\n",
    "\n",
    "    # Use the best model from your cross validation runs above ...\n",
    "    pipeline_lr = Pipeline(stages=[SI1, SI2, SI3, SI4, SI5, SI6, OH1, OH2, OH3, OH4, OH5, OH6, assembler,scaler, lrCvModel.bestModel])\n",
    "    pipeline_rf = Pipeline(stages=[SI1, SI2, SI3, SI4, SI5, SI6, OH1, OH2, OH3, OH4, OH5, OH6, assembler,scaler, rfCvModel.bestModel])\n",
    "     \n",
    "    model_lr = pipeline_lr.fit(inputdf)\n",
    "    model_rf = pipeline_rf.fit(inputdf)\n",
    "\n",
    "    \n",
    "    print \"Model built!!\"\n",
    "    \n",
    "    return pipeline_lr, model_lr, pipeline_rf, model_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model...\n",
      "Model built!!\n"
     ]
    }
   ],
   "source": [
    "# loan_spark as training dataset with label, cv not applicatiable\n",
    "loan_spark_read = spark.read.parquet(\"home/lending_club/loan_sub_kp\").cache()\n",
    "pipeline_lr, model_lr, pipeline_rf, model_rf = build_model(loan_spark_read)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Set up Watson Machine Learning Credentials **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \n",
    "cc_creds = {\n",
    "  \"url\": \"https://ibm-watson-ml.mybluemix.net\",\n",
    "  \"access_key\": \"8I7slbLraBwPGRVdAvhVBs4quUlHxQBfVh9AcsReS3CEYVe+pQs2Lmppeo/ZVIpYHxGxQ3pIogjgEOjN0TGDTcL0h32gVzPkwMbmHXNpi+FQYUqQmv73SQJrb1WXWeZv\",\n",
    "  \"username\": \"0b45b40e-f2e5-43a4-bc0a-55cb076a4ee6\",\n",
    "  \"password\": \"813db8af-b707-4e59-a676-357cfe1ac299\"\n",
    "}\n",
    "\n",
    "\n",
    "dv_creds = {\n",
    "  \"url\": \"https://ibm-watson-ml.mybluemix.net\",\n",
    "  \"access_key\": \"kbXV3OOJ0i2mjGVhB461icjYpZlBFyiIjIpOn/ys0bSNe4rD50whFt1EcTocKgHvHxGxQ3pIogjgEOjN0TGDTcL0h32gVzPkwMbmHXNpi+FQYUqQmv73SQJrb1WXWeZv\",\n",
    "  \"username\": \"7ddbfc51-2af5-4029-8e7f-f609a255fd5b\",\n",
    "  \"password\": \"f5604e9e-7220-4f23-8a42-1ff814a72362\",\n",
    "  \"instance_id\": \"d51854a2-84b2-41db-90f0-ac2419a944f2\"\n",
    "}\n",
    "# Using Dustin's WML creds for now\n",
    "creds = dv_creds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(url):\n",
    "    filename = url.split('/')[-1]\n",
    "    print 'Downloading', filename\n",
    "    http = urllib3.PoolManager()\n",
    "    response = http.request('GET', url)\n",
    "    data = response.data\n",
    "    with open(filename, 'w') as myfile:\n",
    "        myfile.write(data)\n",
    "\n",
    "#download('https://raw.githubusercontent.com/CatherineCao2016/lendingclub/master/deployfuncs.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2017-10-03 14:40:49--  https://github.com/dustinvanstee/lendingclub/raw/master/lendingclub-flask-demo/wml_deployfuncs.py\n",
      "Resolving github.com (github.com)... 192.30.253.113, 192.30.253.112\n",
      "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/dustinvanstee/lendingclub/master/lendingclub-flask-demo/wml_deployfuncs.py [following]\n",
      "--2017-10-03 14:40:50--  https://raw.githubusercontent.com/dustinvanstee/lendingclub/master/lendingclub-flask-demo/wml_deployfuncs.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.48.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.48.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6962 (6.8K) [text/plain]\n",
      "Saving to: ‘wml_deployfuncs.py’\n",
      "\n",
      "     0K ......                                                100% 12.7M=0.001s\n",
      "\n",
      "2017-10-03 14:40:50 (12.7 MB/s) - ‘wml_deployfuncs.py’ saved [6962/6962]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "touch __init__.py\n",
    "rm -rf ./wml_deployfuncs.py\n",
    "wget https://github.com/dustinvanstee/lendingclub/raw/master/lendingclub-flask-demo/wml_deployfuncs.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wml_deployfuncs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model to WML repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Modeling...Model ID:\n",
      "## Published Model Summary ##\n",
      "# Published Model 0 0c7052b8-fe40-49b1-8ce9-19a8ea964e99 lc_lr_defaultprediction\n",
      "# Published Model 1 33a64930-1e16-46d8-bb46-762426a1846f dv2\n",
      "# Published Model 2 5bfab4df-4343-4b11-a3f0-347730135a69 lc_rf_defaultprediction\n",
      "# Published Model 3 82eff54f-8fb9-41f1-87fa-6fec32e5dcd5 Probability Model - CV+Bin2\n",
      "# Published Model 4 d6feb26f-5ba3-4446-a40b-1176948c2cf8 Driver Ranking - CV+Bin2\n",
      "Deleting Model lc_rf_defaultprediction 5bfab4df-4343-4b11-a3f0-347730135a69\n",
      "Successfully deleted model\n",
      "status = 204\n",
      "## Published Model Summary ##\n",
      "# Published Model 0 0c7052b8-fe40-49b1-8ce9-19a8ea964e99 lc_lr_defaultprediction\n",
      "# Published Model 1 32b184b6-2208-4598-a813-58bbbf9d7921 lc_rf_defaultprediction\n",
      "# Published Model 2 33a64930-1e16-46d8-bb46-762426a1846f dv2\n",
      "# Published Model 3 82eff54f-8fb9-41f1-87fa-6fec32e5dcd5 Probability Model - CV+Bin2\n",
      "# Published Model 4 d6feb26f-5ba3-4446-a40b-1176948c2cf8 Driver Ranking - CV+Bin2\n",
      "Deleting Model lc_lr_defaultprediction 0c7052b8-fe40-49b1-8ce9-19a8ea964e99\n",
      "Successfully deleted model\n",
      "status = 204\n"
     ]
    }
   ],
   "source": [
    "loan_spark_read = loan_spark_read.withColumn('label', loan_spark_read['DEFAULT'].cast(DoubleType()))\n",
    "print \"Saving Modeling...Model ID:\"\n",
    "published_model_name_or_id = save_model_by_name(creds, \"lc_rf_defaultprediction\", model_rf, loan_spark_read)\n",
    "published_model_name_or_id = save_model_by_name(creds, \"lc_lr_defaultprediction\", model_lr, loan_spark_read)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Published Model Summary ##\n",
      "# Published Model 0 32b184b6-2208-4598-a813-58bbbf9d7921 lc_rf_defaultprediction\n",
      "# Published Model 1 33a64930-1e16-46d8-bb46-762426a1846f dv2\n",
      "# Published Model 2 82eff54f-8fb9-41f1-87fa-6fec32e5dcd5 Probability Model - CV+Bin2\n",
      "# Published Model 3 d6feb26f-5ba3-4446-a40b-1176948c2cf8 Driver Ranking - CV+Bin2\n",
      "# Published Model 4 e8915a60-0f53-4d34-8a9f-eef64e2a5103 lc_lr_defaultprediction\n",
      "https://ibm-watson-ml.mybluemix.net/v3/wml_instances/d51854a2-84b2-41db-90f0-ac2419a944f2/published_models/32b184b6-2208-4598-a813-58bbbf9d7921/deployments/d56a7a94-8c01-4d01-ba0d-5c481c8bd625/online\n",
      "https://ibm-watson-ml.mybluemix.net/v3/wml_instances/d51854a2-84b2-41db-90f0-ac2419a944f2/published_models/e8915a60-0f53-4d34-8a9f-eef64e2a5103/deployments/249ecd9e-c21c-4c9b-bbfc-cc1e7d3fcd61/online\n"
     ]
    }
   ],
   "source": [
    "published_models_json = get_published_models(creds)\n",
    "rf_scoring_url = deploy_model(creds, published_models_json, \"lc_rf_defaultprediction\")\n",
    "lr_scoring_url = deploy_model(creds, published_models_json, \"lc_lr_defaultprediction\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring: Call REST API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create a JSON Sample record for scoring **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_data = {\n",
    "  \"fields\": ['LOAN_AMNT',\n",
    " 'EMP_LENGTH',\n",
    " 'VERIFICATION_STATUS',\n",
    " 'HOME_OWNERSHIP',\n",
    " 'ANNUAL_INC',\n",
    " 'PURPOSE',\n",
    " 'INQ_LAST_6MTHS',\n",
    " 'OPEN_ACC',\n",
    " 'PUB_REC',\n",
    " 'REVOL_UTIL',\n",
    " 'DTI',\n",
    " 'TOTAL_ACC',\n",
    " 'DELINQ_2YRS',\n",
    " 'EARLIEST_CR_LINE',\n",
    " 'ADDR_STATE',\n",
    " 'TERM',\n",
    " 'DEFAULT',\n",
    " 'EMP_LISTED',\n",
    " 'EMPTY_DESC',\n",
    " 'EMP_NA',\n",
    " 'DELING_EVER',\n",
    " 'TIME_HISTORY'],\n",
    "  \"values\": [\n",
    "    [4500, '< 1 year', 'Verified', 'RENT', 80000, 'major_purchase', 1, 9, 0, 18.3, 5.39, 16, 0, 780969600000000000, 'CA', '36 months', 0, 1, 0, 0, 0, 6148, 0]\n",
    "  ]\n",
    "}\n",
    "\n",
    "sample_json = json.dumps(sample_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Make API call for scoring **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ibm-watson-ml.mybluemix.net/v3/wml_instances/d51854a2-84b2-41db-90f0-ac2419a944f2/published_models/0c7052b8-fe40-49b1-8ce9-19a8ea964e99/deployments/da02c490-7aa6-44bb-854e-de85becea066/online\n"
     ]
    }
   ],
   "source": [
    "print lr_scoring_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"fields\": [\"LOAN_AMNT\", \"EMP_LENGTH\", \"VERIFICATION_STATUS\", \"HOME_OWNERSHIP\", \"ANNUAL_INC\", \"PURPOSE\", \"INQ_LAST_6MTHS\", \"OPEN_ACC\", \"PUB_REC\", \"REVOL_UTIL\", \"DTI\", \"TOTAL_ACC\", \"DELINQ_2YRS\", \"EARLIEST_CR_LINE\", \"ADDR_STATE\", \"TERM\", \"DEFAULT\", \"EMP_LISTED\", \"EMPTY_DESC\", \"EMP_NA\", \"DELING_EVER\", \"TIME_HISTORY\", \"EMP_LENGTHIndex\", \"VERIFICATION_STATUSIndex\", \"HOME_OWNERSHIPIndex\", \"PURPOSEIndex\", \"ADDR_STATEIndex\", \"TERMIndex\", \"EMP_LENGTHclassVec\", \"VERIFICATION_STATUSclassVec\", \"HOME_OWNERSHIPclassVec\", \"PURPOSEclassVec\", \"ADDR_STATEclassVec\", \"TERMclassVec\", \"features_non_scaled\", \"features\", \"rawPrediction\", \"probability\", \"prediction\"],\n",
      "  \"values\": [[4500, \"< 1 year\", \"Verified\", \"RENT\", 80000.0, \"major_purchase\", 1, 9, 0, 18.3, 5.39, 16, 0, 780969600000000000, \"CA\", \"36 months\", 0, 1, 0, 0, 0, 6148, 1.0, 1.0, 0.0, 4.0, 0.0, 0.0, [11, [1], [1.0]], [2, [1], [1.0]], [4, [0], [1.0]], [13, [4], [1.0]], [49, [0], [1.0]], [1, [0], [1.0]], [94, [1, 12, 13, 21, 30, 79, 80, 81, 82, 83, 85, 86, 87, 89, 93], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4500.0, 80000.0, 1.0, 9.0, 18.3, 5.39, 16.0, 1.0, 6148.0]], [94, [1, 12, 13, 21, 30, 79, 80, 81, 82, 83, 85, 86, 87, 89, 93], [3.1315481727072725, 2.1387385246950217, 2.002482300800487, 4.387177343889624, 2.612366870429355, 2.2533332108620012, 0.6033528818383653, 1.251882970557907, 0.9018647867685797, 2.038701401031574, 0.6463351130871458, 0.8067731904777475, 1.4011623956977033, 4.145820391117486, 2.4580319818793375]], [2.591772241027356, -2.591772241027356], [0.9303301742353534, 0.06966982576464667], 0.0]]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Get the scoring endpoint from the WML service\n",
    "scoring_response = score_example(creds, lr_scoring_url, sample_json)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Grab Prediction Value  **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Prediction for this borrower is: 0.0\n",
      "Default Probability for this borrower is: [0.9303301742353534, 0.06966982576464667]\n"
     ]
    }
   ],
   "source": [
    "wml = json.loads(scoring_response)\n",
    "\n",
    "# First zip the fields and values together\n",
    "zipped_wml = zip(wml['fields'], wml['values'].pop())\n",
    "\n",
    "# Next iterate through items and grab the prediction value\n",
    "print \"Default Prediction for this borrower is: \" + str([v for (k,v) in zipped_wml if k == 'prediction'].pop())\n",
    "print \"Default Probability for this borrower is: \" + str([v for (k,v) in zipped_wml if k == 'probability'].pop())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default Prediction App Powered by Watson Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Go to the web app: https://lendingclub-flask-demo.mybluemix.net/#\n",
    "\n",
    "To view the source of this web app, go here https://github.com/dustinvanstee/lendingclub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Retraining and Redeploying -> [WIP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain_and_deploy(creds, loan_spark_read, \"Updated_LR_Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
