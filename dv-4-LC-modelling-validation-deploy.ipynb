{
    "metadata": {
        "celltoolbar": "Raw Cell Format", 
        "language_info": {
            "version": "2.7.11", 
            "file_extension": ".py", 
            "codemirror_mode": {
                "version": 2, 
                "name": "ipython"
            }, 
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "name": "python", 
            "pygments_lexer": "ipython2"
        }, 
        "kernelspec": {
            "display_name": "Python 2 with Spark 2.0", 
            "language": "python", 
            "name": "python2-spark20"
        }
    }, 
    "nbformat": 4, 
    "cells": [
        {
            "metadata": {
                "collapsed": true
            }, 
            "cell_type": "markdown", 
            "source": "## Modeling / Evaluation /Deployment to WML using Pyspark\n<img src=\"https://github.com/CatherineCao2016/lendingclub/raw/master/modeling.png\" width=\"800\" height=\"500\" align=\"middle\"/>\n"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "We are trying to predict the likliehood of default given borrowers data.  \nHere are three ML algorithms are tested using Spark and Pipelines API in pyspark.\n\n1. Logistic Regression\n2. Decision Tree\n3. Random Forest"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "## Import Libraries"
        }, 
        {
            "metadata": {
                "scrolled": false, 
                "slideshow": {
                    "slide_type": "-"
                }, 
                "collapsed": true
            }, 
            "outputs": [], 
            "cell_type": "code", 
            "execution_count": 1, 
            "source": "import ibmdbpy\nfrom ibmdbpy import IdaDataBase, IdaDataFrame\nimport pandas as pd\npd.options.display.max_columns = 999\npd.set_option('display.max_colwidth', 200)\n\nimport warnings\nwarnings.filterwarnings('ignore')\nimport time\nfrom datetime import datetime\nimport math\nimport urllib3, requests, json\n\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.types import DoubleType\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\nfrom pyspark.ml.classification import LogisticRegression, RandomForestClassifier\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\nfrom pyspark.ml.feature import StandardScaler\n"
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "cell_type": "markdown", 
            "source": "## Load Cleaned Data"
        }, 
        {
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "<bound method DataFrame.printSchema of DataFrame[LOAN_STATUS: string, ISSUE_D: bigint, LOAN_AMNT: bigint, EMP_TITLE: string, EMP_LENGTH: string, VERIFICATION_STATUS: string, HOME_OWNERSHIP: string, ANNUAL_INC: double, PURPOSE: string, INQ_LAST_6MTHS: bigint, DESC: string, OPEN_ACC: bigint, PUB_REC: bigint, REVOL_UTIL: double, DTI: double, TOTAL_ACC: bigint, DELINQ_2YRS: bigint, EARLIEST_CR_LINE: bigint, MTHS_SINCE_LAST_DELINQ: double, ADDR_STATE: string, TERM: string, DEFAULT: bigint, EMP_LISTED: bigint, EMPTY_DESC: bigint, EMP_NA: bigint, DELING_EVER: bigint, TIME_HISTORY: bigint]>\n", 
                    "name": "stdout"
                }, 
                {
                    "metadata": {}, 
                    "output_type": "execute_result", 
                    "execution_count": 3, 
                    "data": {
                        "text/plain": "  summary                 ISSUE_D           LOAN_AMNT         ANNUAL_INC  \\\n0   count                   39999               39999              39999   \n1    mean  1.28886233483833523E18  11220.381759543989  69005.63250381262   \n2  stddev   2.8809946600352852E16   7458.321880039553  63903.73691587774   \n3     min     1180656000000000000                 500             4000.0   \n4     max     1322697600000000000               35000          6000000.0   \n\n       INQ_LAST_6MTHS           OPEN_ACC               PUB_REC  \\\n0               39999              39999                 39999   \n1   0.889347233680842  9.304557613940348  0.055451386284657116   \n2  1.1088136654975094  4.414574883524405   0.23817652494183308   \n3                   0                  2                     0   \n4                   8                 44                     4   \n\n           REVOL_UTIL                 DTI           TOTAL_ACC  \\\n0               39999               39999               39999   \n1   48.87473636840911  13.328587714692953  22.113227830695767   \n2  28.313485728157534   6.680935935424673    11.4190903560703   \n3                 0.0                 0.0                   2   \n4                99.9               29.99                  90   \n\n          DELINQ_2YRS        EARLIEST_CR_LINE MTHS_SINCE_LAST_DELINQ  \\\n0               39999                   39999                  39999   \n1  0.1474036850921273   8.5362744012600922E17      35.90692017301288   \n2  0.4959183335662212  2.15614900508990368E17     13.098574359254316   \n3                   0     -757382400000000000                    0.0   \n4                  11     1225497600000000000                  120.0   \n\n               DEFAULT           EMP_LISTED          EMPTY_DESC  \\\n0                39999                39999               39999   \n1  0.14262856571414284   0.9379734493362334  0.3314582864571614   \n2  0.34969803438221314  0.24120678313573807  0.4707432749549588   \n3                    0                    0                   0   \n4                    1                    1                   1   \n\n                EMP_NA          DELING_EVER        TIME_HISTORY  \n0                39999                39999               39999  \n1   0.0271756793919848  0.35395884897122426   5037.440911022775  \n2  0.16259711806690522  0.47820257139793804  2501.1879606625066  \n3                    0                    0                1095  \n4                    1                    1               23892  ", 
                        "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>summary</th>\n      <th>ISSUE_D</th>\n      <th>LOAN_AMNT</th>\n      <th>ANNUAL_INC</th>\n      <th>INQ_LAST_6MTHS</th>\n      <th>OPEN_ACC</th>\n      <th>PUB_REC</th>\n      <th>REVOL_UTIL</th>\n      <th>DTI</th>\n      <th>TOTAL_ACC</th>\n      <th>DELINQ_2YRS</th>\n      <th>EARLIEST_CR_LINE</th>\n      <th>MTHS_SINCE_LAST_DELINQ</th>\n      <th>DEFAULT</th>\n      <th>EMP_LISTED</th>\n      <th>EMPTY_DESC</th>\n      <th>EMP_NA</th>\n      <th>DELING_EVER</th>\n      <th>TIME_HISTORY</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>count</td>\n      <td>39999</td>\n      <td>39999</td>\n      <td>39999</td>\n      <td>39999</td>\n      <td>39999</td>\n      <td>39999</td>\n      <td>39999</td>\n      <td>39999</td>\n      <td>39999</td>\n      <td>39999</td>\n      <td>39999</td>\n      <td>39999</td>\n      <td>39999</td>\n      <td>39999</td>\n      <td>39999</td>\n      <td>39999</td>\n      <td>39999</td>\n      <td>39999</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>mean</td>\n      <td>1.28886233483833523E18</td>\n      <td>11220.381759543989</td>\n      <td>69005.63250381262</td>\n      <td>0.889347233680842</td>\n      <td>9.304557613940348</td>\n      <td>0.055451386284657116</td>\n      <td>48.87473636840911</td>\n      <td>13.328587714692953</td>\n      <td>22.113227830695767</td>\n      <td>0.1474036850921273</td>\n      <td>8.5362744012600922E17</td>\n      <td>35.90692017301288</td>\n      <td>0.14262856571414284</td>\n      <td>0.9379734493362334</td>\n      <td>0.3314582864571614</td>\n      <td>0.0271756793919848</td>\n      <td>0.35395884897122426</td>\n      <td>5037.440911022775</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>stddev</td>\n      <td>2.8809946600352852E16</td>\n      <td>7458.321880039553</td>\n      <td>63903.73691587774</td>\n      <td>1.1088136654975094</td>\n      <td>4.414574883524405</td>\n      <td>0.23817652494183308</td>\n      <td>28.313485728157534</td>\n      <td>6.680935935424673</td>\n      <td>11.4190903560703</td>\n      <td>0.4959183335662212</td>\n      <td>2.15614900508990368E17</td>\n      <td>13.098574359254316</td>\n      <td>0.34969803438221314</td>\n      <td>0.24120678313573807</td>\n      <td>0.4707432749549588</td>\n      <td>0.16259711806690522</td>\n      <td>0.47820257139793804</td>\n      <td>2501.1879606625066</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>min</td>\n      <td>1180656000000000000</td>\n      <td>500</td>\n      <td>4000.0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>-757382400000000000</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1095</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>max</td>\n      <td>1322697600000000000</td>\n      <td>35000</td>\n      <td>6000000.0</td>\n      <td>8</td>\n      <td>44</td>\n      <td>4</td>\n      <td>99.9</td>\n      <td>29.99</td>\n      <td>90</td>\n      <td>11</td>\n      <td>1225497600000000000</td>\n      <td>120.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>23892</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    }
                }
            ], 
            "cell_type": "code", 
            "execution_count": 3, 
            "source": "loan_spark_read = spark.read.parquet(\"home/lending_club/loan_sub_kp\").cache()\n# loan_spark = spark.createDataFrame(loan_sub_kp.drop(['LOAN_STATUS', 'ISSUE_D', 'EMP_TITLE', 'DESC', 'MTHS_SINCE_LAST_DELINQ'], 1)).cache()\nprint loan_spark_read.printSchema\nloan_spark_read.toPandas()\nloan_spark_read.describe().toPandas()\n"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "**Preprocess the data**"
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "cell_type": "code", 
            "execution_count": 4, 
            "source": "# create label column: covert long to double to avoid RF fit error\nloan_spark_read = loan_spark_read.withColumn('label', loan_spark_read['DEFAULT'].cast(DoubleType()))"
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "cell_type": "code", 
            "execution_count": 5, 
            "source": "# One-hot encoder for all categorical varaibles\ncatCols = ['EMP_LENGTH', 'VERIFICATION_STATUS', 'HOME_OWNERSHIP', 'PURPOSE', 'ADDR_STATE', 'TERM']\nfor catCol in catCols:\n    loan_spark_read = StringIndexer(inputCol=catCol, outputCol=catCol+\"Index\").fit(loan_spark_read).transform(loan_spark_read)\n    loan_spark_read = OneHotEncoder(inputCol=catCol+\"Index\", outputCol=catCol+\"classVec\").transform(loan_spark_read)  "
        }, 
        {
            "metadata": {}, 
            "outputs": [], 
            "cell_type": "code", 
            "execution_count": 8, 
            "source": "# Assemble feature vector\nnumCols = ['LOAN_AMNT', 'ANNUAL_INC', 'INQ_LAST_6MTHS', 'OPEN_ACC', 'PUB_REC', 'REVOL_UTIL', 'DTI', 'TOTAL_ACC', 'DELINQ_2YRS', 'EMP_LISTED', 'EMPTY_DESC', 'EMP_NA', 'DELING_EVER', 'TIME_HISTORY']\n\n# Concatenate Numerical and Categorical Features, and then add to Vector Assembler \nassemblerInputs = map(lambda c: c + \"classVec\", catCols) + numCols\nassembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features_non_scaled\")\n# Debug\n# assemblerInputs = numCols\n#assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features_non_scaled\")\nloan_spark = assembler.transform(loan_spark_read)\n\n\nscaler = StandardScaler(withMean=False, withStd=True, inputCol=\"features_non_scaled\", outputCol=\"features\")\nscalerModel = scaler.fit(loan_spark)\nloan_spark = scalerModel.transform(loan_spark)\n\n# keep useful variables\nselectedcols = [\"label\", \"features\"]\nloan_model = loan_spark.select(selectedcols)\n"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "** Split the data into training and testing sets  **"
        }, 
        {
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "Training set size: 27877\nTesting set size: 12122\nDistribution of Default and Non-Default in trainingData is:  [Row(label=0.0, count=23913), Row(label=1.0, count=3964)]\n", 
                    "name": "stdout"
                }
            ], 
            "cell_type": "code", 
            "execution_count": 9, 
            "source": "trainingData, testData = loan_model.randomSplit([0.7, 0.3], seed = 82)\nprint \"Training set size: \" + str(trainingData.count())\nprint \"Testing set size: \" + str(testData.count())\nprint \"Distribution of Default and Non-Default in trainingData is: \", trainingData.groupBy(\"label\").count().take(3)"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "## Build Models\n\nHere is the method that was used to create model // model pipelines\n\n1.  Create Manual Logistic Regression run with Grid parameter search\n2.  Create Manual Decision Tree run with Grid parameter search\n3.  Create Manual Random Forest run with Grid parameter search\n\n4. Then build a pipeline using the best models found from grid search.\n\n5. Proceed to WML deployment "
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "### Logistic Regression\n** Use CrossValidator and ParamGridBuilder to search for best model **"
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "cell_type": "code", 
            "execution_count": 17, 
            "source": "# Create initial LogisticRegression model\nlr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", threshold=0.3)\n\n# Create ParamGrid for Cross Validation\nparamGrid = (ParamGridBuilder()\n             .addGrid(lr.regParam, [0.001, 0.1])\n             .addGrid(lr.elasticNetParam, [0.0,1.0])\n             .addGrid(lr.maxIter, [100])\n             .build())\n\n\nevaluator = BinaryClassificationEvaluator()\n\n# Create 5-fold CrossValidator\ncv = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=2)\n\n# Run cross validations\nlrCvModel = cv.fit(trainingData)"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "** Use BinaryClassificationEvaluator to evaluate the model **\n\nNote that the default metric for the BinaryClassificationEvaluator is areaUnderROC"
        }, 
        {
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "areaUnderROC for LR: 0.690960338722\nCross tab for prediction vs actual table\n+----------------+----+---+\n|label_prediction| 0.0|1.0|\n+----------------+----+---+\n|             1.0|1512|229|\n|             0.0|9958|423|\n+----------------+----+---+\n\n", 
                    "name": "stdout"
                }
            ], 
            "cell_type": "code", 
            "execution_count": 18, 
            "source": "# Use test set here so we can measure the accuracy of our model on new data\nlr_uroc = evaluator.evaluate(lrCvModel.transform(testData))\n\nprint \"areaUnderROC for LR: \" + str(lr_uroc)\n\nprint \"Cross tab for prediction vs actual table\"\nlrCvModel.transform(testData).stat.crosstab(\"label\", \"prediction\").show()\n# lrCvModel.bestModel.transform(testData).toPandas()\n#print lrCvModel.bestModel.coefficients\n#print lrCvModel.bestModel.intercept\n"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "### Decision Tree"
        }, 
        {
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "numNodes =  921\ndepth =  10\nareaUnderROC for DT: 0.47766473024\nCross tab for prediction vs actual table\n+----------------+-----+---+\n|label_prediction|  0.0|1.0|\n+----------------+-----+---+\n|             1.0| 1651| 90|\n|             0.0|10136|245|\n+----------------+-----+---+\n\n", 
                    "name": "stdout"
                }
            ], 
            "cell_type": "code", 
            "execution_count": 22, 
            "source": "from pyspark.ml.classification import DecisionTreeClassifier\n\n# Create initial Decision Tree Model\ndt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\", maxDepth=5)\n\n\n# Hyperparameter Tuning\nparamGrid = (ParamGridBuilder()\n             .addGrid(dt.maxDepth, [10])\n             .addGrid(dt.maxBins, [40])\n             .build())\n\n\n# Create 5-fold CrossValidator\ncv = CrossValidator(estimator=dt, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n\n# Run cross validations\ndtCvModel = cv.fit(trainingData)\n\nprint \"numNodes = \", dtCvModel.bestModel.numNodes\nprint \"depth = \", dtCvModel.bestModel.depth\n\n\n# Evaluate the model\n\npredictions = dtCvModel.transform(testData)\n\nevaluator = BinaryClassificationEvaluator()\ndt_uroc = evaluator.evaluate(predictions)\n\nprint \"areaUnderROC for DT: \" + str(dt_uroc)\nprint \"Cross tab for prediction vs actual table\"\ndtCvModel.transform(testData).stat.crosstab(\"label\", \"prediction\").show()"
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "cell_type": "markdown", 
            "source": "### Random Forest"
        }, 
        {
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "areaUnderROC for RF: 0.677956226197\nCross tab for prediction vs actual table\n+----------------+-----+\n|label_prediction|  0.0|\n+----------------+-----+\n|             1.0| 1741|\n|             0.0|10381|\n+----------------+-----+\n\n", 
                    "name": "stdout"
                }
            ], 
            "cell_type": "code", 
            "execution_count": 19, 
            "source": "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n\nparamGrid = (ParamGridBuilder()\n             .addGrid(rf.maxDepth, [2, 6])\n             .addGrid(rf.maxBins, [20, 40])\n             .addGrid(rf.numTrees, [5, 20])\n             .build())\n\ncv = CrossValidator(estimator=rf, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n\n# Run cross validations.  This can take about 6 minutes since it is training over 20 trees!\nrfCvModel = cv.fit(trainingData)\n\npredictions = rfCvModel.transform(testData)\n\nrf_uroc = evaluator.evaluate(predictions)\n\nprint \"areaUnderROC for RF: \" + str(rf_uroc) #0.6918242957971713\nprint \"Cross tab for prediction vs actual table\"\nrfCvModel.transform(testData).stat.crosstab(\"label\", \"prediction\").show()"
        }, 
        {
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "areaUnderROC for LR: 0.690960338722\nareaUnderROC for DT: 0.47766473024\nareaUnderROC for RF: 0.677956226197\n", 
                    "name": "stdout"
                }
            ], 
            "cell_type": "code", 
            "execution_count": 23, 
            "source": "print \"areaUnderROC for LR: \" + str(lr_uroc)\nprint \"areaUnderROC for DT: \" + str(dt_uroc)\nprint \"areaUnderROC for RF: \" + str(rf_uroc) #0.6918242957971713\n"
        }, 
        {
            "metadata": {}, 
            "outputs": [
                {
                    "metadata": {}, 
                    "output_type": "execute_result", 
                    "execution_count": 24, 
                    "data": {
                        "text/plain": "SparseVector(94, {0: 0.002, 1: 0.0024, 2: 0.0034, 3: 0.0023, 4: 0.0056, 5: 0.0018, 6: 0.002, 7: 0.0026, 8: 0.0, 9: 0.0019, 10: 0.0038, 11: 0.0103, 12: 0.0108, 13: 0.0059, 14: 0.0127, 15: 0.0021, 16: 0.002, 17: 0.0018, 18: 0.0221, 19: 0.0028, 20: 0.0043, 21: 0.0058, 22: 0.0324, 23: 0.0027, 24: 0.0006, 25: 0.0019, 26: 0.0028, 27: 0.0007, 28: 0.001, 29: 0.0038, 30: 0.0044, 31: 0.003, 32: 0.0058, 33: 0.0004, 34: 0.0027, 35: 0.001, 36: 0.0016, 37: 0.0022, 38: 0.0038, 39: 0.002, 40: 0.001, 41: 0.0025, 42: 0.0014, 43: 0.0005, 44: 0.0007, 45: 0.0012, 46: 0.0031, 47: 0.0011, 48: 0.0018, 49: 0.0016, 50: 0.0054, 51: 0.0006, 52: 0.0003, 53: 0.0002, 54: 0.0029, 55: 0.0017, 56: 0.0012, 58: 0.0007, 59: 0.0007, 60: 0.001, 61: 0.0018, 62: 0.0006, 63: 0.0014, 64: 0.0008, 65: 0.0007, 66: 0.0017, 67: 0.0009, 68: 0.0005, 69: 0.0012, 70: 0.0011, 71: 0.0013, 72: 0.001, 74: 0.0003, 78: 0.0011, 79: 0.2323, 80: 0.055, 81: 0.0835, 82: 0.0698, 83: 0.034, 84: 0.0266, 85: 0.1285, 86: 0.0304, 87: 0.0303, 88: 0.0105, 89: 0.0217, 90: 0.0011, 91: 0.0065, 92: 0.0107, 93: 0.0337})"
                    }
                }
            ], 
            "cell_type": "code", 
            "execution_count": 24, 
            "source": "rfCvModel.bestModel.featureImportances"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "## Model Deployment via Watson Machine Learning Service(WML)"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "<img src=\"https://github.com/CatherineCao2016/lendingclub/raw/master/depolyment.png\" width=\"800\" height=\"500\" align=\"middle\"/>"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "**Create Pipeline for WML**"
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "cell_type": "code", 
            "execution_count": 54, 
            "source": "# inputdf should have a non-doubt DEFAULT column\n\ndef build_model(inputdf):\n    \n    inputdf = inputdf.withColumn('label', inputdf['DEFAULT'].cast(DoubleType()))\n    \n    catCols = ['EMP_LENGTH', 'VERIFICATION_STATUS', 'HOME_OWNERSHIP', 'PURPOSE', 'ADDR_STATE', 'TERM']\n    \n    # to_do: is it possible use for loop to produce the following? so we could user-define variable list\n    SI1 = StringIndexer(inputCol='EMP_LENGTH', outputCol='EMP_LENGTH'+\"Index\")\n    SI2 = StringIndexer(inputCol='VERIFICATION_STATUS', outputCol='VERIFICATION_STATUS'+'Index')\n    SI3 = StringIndexer(inputCol='HOME_OWNERSHIP', outputCol='HOME_OWNERSHIP'+'Index')\n    SI4 = StringIndexer(inputCol='PURPOSE', outputCol='PURPOSE'+'Index')\n    SI5 = StringIndexer(inputCol='ADDR_STATE', outputCol='ADDR_STATE'+'Index')\n    SI6 = StringIndexer(inputCol='TERM', outputCol='TERM'+'Index')\n\n    OH1 = OneHotEncoder(inputCol='EMP_LENGTH' + 'Index', outputCol='EMP_LENGTH' + 'classVec')\n    OH2 = OneHotEncoder(inputCol='VERIFICATION_STATUS' + 'Index', outputCol='VERIFICATION_STATUS' + 'classVec')\n    OH3 = OneHotEncoder(inputCol='HOME_OWNERSHIP' + 'Index', outputCol='HOME_OWNERSHIP' + 'classVec')\n    OH4 = OneHotEncoder(inputCol='PURPOSE' + 'Index', outputCol='PURPOSE' + 'classVec')\n    OH5 = OneHotEncoder(inputCol='ADDR_STATE' + 'Index', outputCol='ADDR_STATE' + 'classVec')\n    OH6 = OneHotEncoder(inputCol='TERM' + 'Index', outputCol='TERM' + 'classVec')\n    \n    numCols = ['LOAN_AMNT', 'ANNUAL_INC', 'INQ_LAST_6MTHS', 'OPEN_ACC', 'PUB_REC', 'REVOL_UTIL', 'DTI', 'TOTAL_ACC', 'DELINQ_2YRS', 'EMP_LISTED', 'EMPTY_DESC', 'EMP_NA', 'DELING_EVER', 'TIME_HISTORY']\n    \n    assemblerInputs = map(lambda c: c + \"classVec\", catCols) + numCols\n    \n    assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features_non_scaled\")\n    \n    scaler = StandardScaler(withMean=False, withStd=True, inputCol=\"features_non_scaled\", outputCol=\"features\")\n    #scalerModel = scaler.fit(loan_spark)\n    #loan_spark = scalerModel.transform(loan_spark)\n    \n    \n    \n    print \"Training Model...\"\n    \n    #lr_final = LogisticRegression(maxIter=10, regParam=0.1, elasticNetParam=0.0, threshold = 0.5, labelCol=\"label\", featuresCol=\"features\")\n    \n    rf_final_model = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", maxDepth = 6, maxBins = 60, numTrees = 20)\n\n    # Use the best model from your cross validation runs above ...\n    pipeline_lr = Pipeline(stages=[SI1, SI2, SI3, SI4, SI5, SI6, OH1, OH2, OH3, OH4, OH5, OH6, assembler,scaler, lrCvModel.bestModel])\n    pipeline_rf = Pipeline(stages=[SI1, SI2, SI3, SI4, SI5, SI6, OH1, OH2, OH3, OH4, OH5, OH6, assembler,scaler, rfCvModel.bestModel])\n     \n    model_lr = pipeline_lr.fit(inputdf)\n    model_rf = pipeline_rf.fit(inputdf)\n\n    \n    print \"Model built!!\"\n    \n    return pipeline_lr, model_lr, pipeline_rf, model_rf"
        }, 
        {
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "Training Model...\nModel built!!\n", 
                    "name": "stdout"
                }
            ], 
            "cell_type": "code", 
            "execution_count": 55, 
            "source": "# loan_spark as training dataset with label, cv not applicatiable\nloan_spark_read = spark.read.parquet(\"home/lending_club/loan_sub_kp\").cache()\npipeline_lr, model_lr, pipeline_rf, model_rf = build_model(loan_spark_read)"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "** Set up Watson Machine Learning Credentials **"
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "cell_type": "code", 
            "execution_count": 56, 
            "source": "# \ncc_creds = {\n  \"url\": \"https://ibm-watson-ml.mybluemix.net\",\n  \"access_key\": \"8I7slbLraBwPGRVdAvhVBs4quUlHxQBfVh9AcsReS3CEYVe+pQs2Lmppeo/ZVIpYHxGxQ3pIogjgEOjN0TGDTcL0h32gVzPkwMbmHXNpi+FQYUqQmv73SQJrb1WXWeZv\",\n  \"username\": \"0b45b40e-f2e5-43a4-bc0a-55cb076a4ee6\",\n  \"password\": \"813db8af-b707-4e59-a676-357cfe1ac299\"\n}\n\n\ndv_creds = {\n  \"url\": \"https://ibm-watson-ml.mybluemix.net\",\n  \"access_key\": \"kbXV3OOJ0i2mjGVhB461icjYpZlBFyiIjIpOn/ys0bSNe4rD50whFt1EcTocKgHvHxGxQ3pIogjgEOjN0TGDTcL0h32gVzPkwMbmHXNpi+FQYUqQmv73SQJrb1WXWeZv\",\n  \"username\": \"7ddbfc51-2af5-4029-8e7f-f609a255fd5b\",\n  \"password\": \"f5604e9e-7220-4f23-8a42-1ff814a72362\",\n  \"instance_id\": \"d51854a2-84b2-41db-90f0-ac2419a944f2\"\n}\n# Using Dustin's WML creds for now\ncreds = dv_creds"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "## UDFs"
        }, 
        {
            "metadata": {}, 
            "outputs": [], 
            "cell_type": "code", 
            "execution_count": 57, 
            "source": "def download(url):\n    filename = url.split('/')[-1]\n    print 'Downloading', filename\n    http = urllib3.PoolManager()\n    response = http.request('GET', url)\n    data = response.data\n    with open(filename, 'w') as myfile:\n        myfile.write(data)\n\n#download('https://raw.githubusercontent.com/CatherineCao2016/lendingclub/master/deployfuncs.py')"
        }, 
        {
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "--2017-10-03 14:40:49--  https://github.com/dustinvanstee/lendingclub/raw/master/lendingclub-flask-demo/wml_deployfuncs.py\nResolving github.com (github.com)... 192.30.253.113, 192.30.253.112\nConnecting to github.com (github.com)|192.30.253.113|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://raw.githubusercontent.com/dustinvanstee/lendingclub/master/lendingclub-flask-demo/wml_deployfuncs.py [following]\n--2017-10-03 14:40:50--  https://raw.githubusercontent.com/dustinvanstee/lendingclub/master/lendingclub-flask-demo/wml_deployfuncs.py\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.48.133\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.48.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 6962 (6.8K) [text/plain]\nSaving to: \u2018wml_deployfuncs.py\u2019\n\n     0K ......                                                100% 12.7M=0.001s\n\n2017-10-03 14:40:50 (12.7 MB/s) - \u2018wml_deployfuncs.py\u2019 saved [6962/6962]\n\n", 
                    "name": "stderr"
                }
            ], 
            "cell_type": "code", 
            "execution_count": 71, 
            "source": "%%bash\ntouch __init__.py\nrm -rf ./wml_deployfuncs.py\nwget https://github.com/dustinvanstee/lendingclub/raw/master/lendingclub-flask-demo/wml_deployfuncs.py"
        }, 
        {
            "metadata": {}, 
            "outputs": [], 
            "cell_type": "code", 
            "execution_count": 72, 
            "source": "import wml_deployfuncs"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "### Save the model to WML repository"
        }, 
        {
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "Saving Modeling...Model ID:\n## Published Model Summary ##\n# Published Model 0 0c7052b8-fe40-49b1-8ce9-19a8ea964e99 lc_lr_defaultprediction\n# Published Model 1 33a64930-1e16-46d8-bb46-762426a1846f dv2\n# Published Model 2 5bfab4df-4343-4b11-a3f0-347730135a69 lc_rf_defaultprediction\n# Published Model 3 82eff54f-8fb9-41f1-87fa-6fec32e5dcd5 Probability Model - CV+Bin2\n# Published Model 4 d6feb26f-5ba3-4446-a40b-1176948c2cf8 Driver Ranking - CV+Bin2\nDeleting Model lc_rf_defaultprediction 5bfab4df-4343-4b11-a3f0-347730135a69\nSuccessfully deleted model\nstatus = 204\n## Published Model Summary ##\n# Published Model 0 0c7052b8-fe40-49b1-8ce9-19a8ea964e99 lc_lr_defaultprediction\n# Published Model 1 32b184b6-2208-4598-a813-58bbbf9d7921 lc_rf_defaultprediction\n# Published Model 2 33a64930-1e16-46d8-bb46-762426a1846f dv2\n# Published Model 3 82eff54f-8fb9-41f1-87fa-6fec32e5dcd5 Probability Model - CV+Bin2\n# Published Model 4 d6feb26f-5ba3-4446-a40b-1176948c2cf8 Driver Ranking - CV+Bin2\nDeleting Model lc_lr_defaultprediction 0c7052b8-fe40-49b1-8ce9-19a8ea964e99\nSuccessfully deleted model\nstatus = 204\n", 
                    "name": "stdout"
                }
            ], 
            "cell_type": "code", 
            "execution_count": 69, 
            "source": "loan_spark_read = loan_spark_read.withColumn('label', loan_spark_read['DEFAULT'].cast(DoubleType()))\nprint \"Saving Modeling...Model ID:\"\npublished_model_name_or_id = save_model_by_name(creds, \"lc_rf_defaultprediction\", model_rf, loan_spark_read)\npublished_model_name_or_id = save_model_by_name(creds, \"lc_lr_defaultprediction\", model_lr, loan_spark_read)\n"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "### Deploy the saved model"
        }, 
        {
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "## Published Model Summary ##\n# Published Model 0 32b184b6-2208-4598-a813-58bbbf9d7921 lc_rf_defaultprediction\n# Published Model 1 33a64930-1e16-46d8-bb46-762426a1846f dv2\n# Published Model 2 82eff54f-8fb9-41f1-87fa-6fec32e5dcd5 Probability Model - CV+Bin2\n# Published Model 3 d6feb26f-5ba3-4446-a40b-1176948c2cf8 Driver Ranking - CV+Bin2\n# Published Model 4 e8915a60-0f53-4d34-8a9f-eef64e2a5103 lc_lr_defaultprediction\nhttps://ibm-watson-ml.mybluemix.net/v3/wml_instances/d51854a2-84b2-41db-90f0-ac2419a944f2/published_models/32b184b6-2208-4598-a813-58bbbf9d7921/deployments/d56a7a94-8c01-4d01-ba0d-5c481c8bd625/online\nhttps://ibm-watson-ml.mybluemix.net/v3/wml_instances/d51854a2-84b2-41db-90f0-ac2419a944f2/published_models/e8915a60-0f53-4d34-8a9f-eef64e2a5103/deployments/249ecd9e-c21c-4c9b-bbfc-cc1e7d3fcd61/online\n", 
                    "name": "stdout"
                }
            ], 
            "cell_type": "code", 
            "execution_count": 70, 
            "source": "published_models_json = get_published_models(creds)\nrf_scoring_url = deploy_model(creds, published_models_json, \"lc_rf_defaultprediction\")\nlr_scoring_url = deploy_model(creds, published_models_json, \"lc_lr_defaultprediction\")\n\n"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "### Scoring: Call REST API"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "** Create a JSON Sample record for scoring **"
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "cell_type": "code", 
            "execution_count": 61, 
            "source": "sample_data = {\n  \"fields\": ['LOAN_AMNT',\n 'EMP_LENGTH',\n 'VERIFICATION_STATUS',\n 'HOME_OWNERSHIP',\n 'ANNUAL_INC',\n 'PURPOSE',\n 'INQ_LAST_6MTHS',\n 'OPEN_ACC',\n 'PUB_REC',\n 'REVOL_UTIL',\n 'DTI',\n 'TOTAL_ACC',\n 'DELINQ_2YRS',\n 'EARLIEST_CR_LINE',\n 'ADDR_STATE',\n 'TERM',\n 'DEFAULT',\n 'EMP_LISTED',\n 'EMPTY_DESC',\n 'EMP_NA',\n 'DELING_EVER',\n 'TIME_HISTORY'],\n  \"values\": [\n    [4500, '< 1 year', 'Verified', 'RENT', 80000, 'major_purchase', 1, 9, 0, 18.3, 5.39, 16, 0, 780969600000000000, 'CA', '36 months', 0, 1, 0, 0, 0, 6148, 0]\n  ]\n}\n\nsample_json = json.dumps(sample_data)"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "** Make API call for scoring **"
        }, 
        {
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "https://ibm-watson-ml.mybluemix.net/v3/wml_instances/d51854a2-84b2-41db-90f0-ac2419a944f2/published_models/0c7052b8-fe40-49b1-8ce9-19a8ea964e99/deployments/da02c490-7aa6-44bb-854e-de85becea066/online\n", 
                    "name": "stdout"
                }
            ], 
            "cell_type": "code", 
            "execution_count": 62, 
            "source": "print lr_scoring_url"
        }, 
        {
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "{\n  \"fields\": [\"LOAN_AMNT\", \"EMP_LENGTH\", \"VERIFICATION_STATUS\", \"HOME_OWNERSHIP\", \"ANNUAL_INC\", \"PURPOSE\", \"INQ_LAST_6MTHS\", \"OPEN_ACC\", \"PUB_REC\", \"REVOL_UTIL\", \"DTI\", \"TOTAL_ACC\", \"DELINQ_2YRS\", \"EARLIEST_CR_LINE\", \"ADDR_STATE\", \"TERM\", \"DEFAULT\", \"EMP_LISTED\", \"EMPTY_DESC\", \"EMP_NA\", \"DELING_EVER\", \"TIME_HISTORY\", \"EMP_LENGTHIndex\", \"VERIFICATION_STATUSIndex\", \"HOME_OWNERSHIPIndex\", \"PURPOSEIndex\", \"ADDR_STATEIndex\", \"TERMIndex\", \"EMP_LENGTHclassVec\", \"VERIFICATION_STATUSclassVec\", \"HOME_OWNERSHIPclassVec\", \"PURPOSEclassVec\", \"ADDR_STATEclassVec\", \"TERMclassVec\", \"features_non_scaled\", \"features\", \"rawPrediction\", \"probability\", \"prediction\"],\n  \"values\": [[4500, \"< 1 year\", \"Verified\", \"RENT\", 80000.0, \"major_purchase\", 1, 9, 0, 18.3, 5.39, 16, 0, 780969600000000000, \"CA\", \"36 months\", 0, 1, 0, 0, 0, 6148, 1.0, 1.0, 0.0, 4.0, 0.0, 0.0, [11, [1], [1.0]], [2, [1], [1.0]], [4, [0], [1.0]], [13, [4], [1.0]], [49, [0], [1.0]], [1, [0], [1.0]], [94, [1, 12, 13, 21, 30, 79, 80, 81, 82, 83, 85, 86, 87, 89, 93], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4500.0, 80000.0, 1.0, 9.0, 18.3, 5.39, 16.0, 1.0, 6148.0]], [94, [1, 12, 13, 21, 30, 79, 80, 81, 82, 83, 85, 86, 87, 89, 93], [3.1315481727072725, 2.1387385246950217, 2.002482300800487, 4.387177343889624, 2.612366870429355, 2.2533332108620012, 0.6033528818383653, 1.251882970557907, 0.9018647867685797, 2.038701401031574, 0.6463351130871458, 0.8067731904777475, 1.4011623956977033, 4.145820391117486, 2.4580319818793375]], [2.591772241027356, -2.591772241027356], [0.9303301742353534, 0.06966982576464667], 0.0]]\n}\n", 
                    "name": "stdout"
                }
            ], 
            "cell_type": "code", 
            "execution_count": 63, 
            "source": "# Get the scoring endpoint from the WML service\nscoring_response = score_example(creds, lr_scoring_url, sample_json)\n"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "** Grab Prediction Value  **"
        }, 
        {
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "Default Prediction for this borrower is: 0.0\nDefault Probability for this borrower is: [0.9303301742353534, 0.06966982576464667]\n", 
                    "name": "stdout"
                }
            ], 
            "cell_type": "code", 
            "execution_count": 64, 
            "source": "wml = json.loads(scoring_response)\n\n# First zip the fields and values together\nzipped_wml = zip(wml['fields'], wml['values'].pop())\n\n# Next iterate through items and grab the prediction value\nprint \"Default Prediction for this borrower is: \" + str([v for (k,v) in zipped_wml if k == 'prediction'].pop())\nprint \"Default Probability for this borrower is: \" + str([v for (k,v) in zipped_wml if k == 'probability'].pop())"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "## Default Prediction App Powered by Watson Machine Learning"
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "cell_type": "markdown", 
            "source": "Go to the web app: https://lendingclub-flask-demo.mybluemix.net/#\n\nTo view the source of this web app, go here https://github.com/dustinvanstee/lendingclub"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "## Model Retraining and Redeploying -> [WIP]"
        }, 
        {
            "metadata": {}, 
            "outputs": [], 
            "cell_type": "code", 
            "execution_count": 73, 
            "source": "# retrain_and_deploy(creds, loan_spark_read, \"Updated_LR_Model\")"
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "cell_type": "code", 
            "execution_count": null, 
            "source": ""
        }
    ], 
    "nbformat_minor": 1
}